{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6yHVsVm82VW",
        "outputId": "91d11142-7591-4bee-c300-8c0f67dcbc3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/morshdy/miniconda3/lib/python3.12/site-packages (4.47.1)\n",
            "Requirement already satisfied: langchain in /home/morshdy/miniconda3/lib/python3.12/site-packages (0.3.7)\n",
            "Requirement already satisfied: datasets in /home/morshdy/miniconda3/lib/python3.12/site-packages (1.12.1)\n",
            "Requirement already satisfied: torch in /home/morshdy/miniconda3/lib/python3.12/site-packages (2.4.1)\n",
            "Requirement already satisfied: scikit-learn in /home/morshdy/miniconda3/lib/python3.12/site-packages (1.5.1)\n",
            "Requirement already satisfied: pandas in /home/morshdy/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
            "Requirement already satisfied: filelock in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from transformers) (4.49.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (0.3.15)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (0.1.142)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill in /home/morshdy/miniconda3/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
            "Collecting tqdm>=4.27 (from transformers)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Requirement already satisfied: xxhash in /home/morshdy/miniconda3/lib/python3.12/site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /home/morshdy/miniconda3/lib/python3.12/site-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.9.0)\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /home/morshdy/miniconda3/lib/python3.12/site-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /home/morshdy/miniconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /home/morshdy/miniconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: anyio in /home/morshdy/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/morshdy/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.2)\n",
            "Requirement already satisfied: sniffio in /home/morshdy/miniconda3/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /home/morshdy/miniconda3/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain) (2.1)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Installing collected packages: tqdm, datasets\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.49.0\n",
            "    Uninstalling tqdm-4.49.0:\n",
            "      Successfully uninstalled tqdm-4.49.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 1.12.1\n",
            "    Uninstalling datasets-1.12.1:\n",
            "      Successfully uninstalled datasets-1.12.1\n",
            "Successfully installed datasets-3.2.0 tqdm-4.67.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers langchain datasets torch scikit-learn pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "63zfq3esG5F_"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1dAbs11vG6et"
      },
      "outputs": [],
      "source": [
        "file_path = 'Shuffled_Formatted_Code_Dataset.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "class CodeDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            row['code'],\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        label = torch.tensor(row['label'], dtype=torch.long)\n",
        "        return inputs, label\n",
        "\n",
        "# Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
        "max_length = 512\n",
        "\n",
        "test_dataset = CodeDataset(data, tokenizer, max_length)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzZB0eDOG8V2",
        "outputId": "8e387958-0f99-4ec3-d1b1-d160cb20988f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-27 20:54:49.642245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1735325689.663989  185214 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1735325689.670570  185214 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-27 20:54:49.692787: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"microsoft/codebert-base\", num_labels=2)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kqQnv5ItG-BN"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            input_ids = inputs['input_ids'].squeeze(1).to(device)\n",
        "            attention_mask = inputs['attention_mask'].squeeze(1).to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            preds = torch.argmax(outputs.logits, dim=1)\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    report = classification_report(true_labels, predictions, target_names=[\"Human\", \"AI\"])\n",
        "    return accuracy, report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZW0FpZ8HATl",
        "outputId": "43701a62-be67-4f3d-d3a8-781cffa1eefe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance Before Prompt Engineering:\n",
            "Accuracy: 0.5\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.50      1.00      0.67       126\n",
            "          AI       0.00      0.00      0.00       126\n",
            "\n",
            "    accuracy                           0.50       252\n",
            "   macro avg       0.25      0.50      0.33       252\n",
            "weighted avg       0.25      0.50      0.33       252\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/morshdy/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/morshdy/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/morshdy/miniconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy_before, report_before = evaluate_model(model, test_loader)\n",
        "print(\"Performance Before Prompt Engineering:\")\n",
        "print(f\"Accuracy: {accuracy_before}\")\n",
        "print(f\"Classification Report:\\n{report_before}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "6OIeZhOPHDxf"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "\n",
        "# Escaped examples for Few-Shot Prompt\n",
        "examples = [\n",
        "    {\n",
        "        \"language\": \"Java\",\n",
        "        \"code\": \"\"\"// This function reverses a string based on a given condition\n",
        "class Solution {{\n",
        "    public String finalString(String s) {{\n",
        "        StringBuilder nm = new StringBuilder();\n",
        "        for (char c : s.toCharArray()) {{\n",
        "            if (c == 'i') {{\n",
        "                nm.reverse();\n",
        "            }} else {{\n",
        "                nm.append(c);\n",
        "            }}\n",
        "        }}\n",
        "        return nm.toString();\n",
        "    }}\n",
        "}}\"\"\",\n",
        "        \"label\": \"Human\"\n",
        "    },\n",
        "    {\n",
        "        \"language\": \"Java\",\n",
        "        \"code\": \"\"\"// AI-Generated: This function finds the minimum absolute difference\n",
        "public class Solution {{\n",
        "    public int minAbsoluteDifference(List<Integer> nums, int x) {{\n",
        "        TreeMap<Integer, Integer> map = new TreeMap<>();\n",
        "        map.put(nums.get(0), 0);\n",
        "        int n = nums.size();\n",
        "        int minDiff = Integer.MAX_VALUE;\n",
        "\n",
        "        for (int i = 1; i < n; i++) {{\n",
        "            if (i >= x) {{\n",
        "                map.remove(nums.get(i - x));\n",
        "            }}\n",
        "            Integer lower = map.floorKey(nums.get(i));\n",
        "            Integer higher = map.ceilingKey(nums.get(i));\n",
        "            if (lower != null) {{\n",
        "                minDiff = Math.min(minDiff, Math.abs(nums.get(i) - lower));\n",
        "            }}\n",
        "            if (higher != null) {{\n",
        "                minDiff = Math.min(minDiff, Math.abs(nums.get(i) - higher));\n",
        "            }}\n",
        "            map.put(nums.get(i), i);\n",
        "        }}\n",
        "        return minDiff;\n",
        "    }}\n",
        "}}\"\"\",\n",
        "        \"label\": \"AI\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Prompt Template\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"language\", \"code\", \"label\"],\n",
        "    template=\"Language: {language}\\nCode:\\n{code}\\nLabel: {label}\\n\"\n",
        ")\n",
        "\n",
        "# Few-Shot Prompt Template\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    suffix=\"Language: {language}\\nCode:\\n{code}\\nLabel:\",\n",
        "    input_variables=[\"language\", \"code\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "kJ29D1q6HG9P"
      },
      "outputs": [],
      "source": [
        "class PromptedCodeDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length):\n",
        "        self.dataframe = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.dataframe.iloc[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            few_shot_prompt.format(language=row['language'], code=row['code']),\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        label = torch.tensor(row['label'], dtype=torch.long)\n",
        "        return inputs, label\n",
        "\n",
        "prompted_test_dataset = PromptedCodeDataset(data, tokenizer, max_length)\n",
        "prompted_test_loader = DataLoader(prompted_test_dataset, batch_size=8, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15Ewj4Y8HI2Q",
        "outputId": "22b8835a-db2f-497f-ba4a-4241a5854892"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance After Prompt Engineering:\n",
            "Accuracy: 0.5\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Human       0.50      1.00      0.67       126\n",
            "          AI       0.00      0.00      0.00       126\n",
            "\n",
            "    accuracy                           0.50       252\n",
            "   macro avg       0.25      0.50      0.33       252\n",
            "weighted avg       0.25      0.50      0.33       252\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy_after, report_after = evaluate_model(model, prompted_test_loader)\n",
        "print(\"Performance After Prompt Engineering:\")\n",
        "print(f\"Accuracy: {accuracy_after}\")\n",
        "print(f\"Classification Report:\\n{report_after}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKrc00imHKoa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
